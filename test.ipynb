{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sayantan Datta\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from typing import Tuple\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import os\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the model and creating the predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained('./emotion_detection_model')\n",
    "    return tokenizer, model\n",
    "\n",
    "def predict_top_emotions(text: str, top_k=3) -> Tuple[list, list]:\n",
    "    \"\"\"\n",
    "    Predicts top K emotions from text using the loaded model\n",
    "    Returns tuple of (emotions, confidences)\n",
    "    \"\"\"\n",
    "    tokenizer, model = load_model()\n",
    "    # Prepare the input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512, padding=True)\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get top K predictions\n",
    "    top_k_probs, top_k_indices = torch.topk(predictions, top_k, dim=1)\n",
    "    \n",
    "    # Map the predictions to emotion labels\n",
    "    emotion_map = {\n",
    "        0: \"sadness\",\n",
    "        1: \"joy\",\n",
    "        2: \"love\",\n",
    "        3: \"anger\",\n",
    "        4: \"fear\",\n",
    "        5: \"surprise\"\n",
    "    }\n",
    "    \n",
    "    top_k_emotions = [emotion_map[idx.item()] for idx in top_k_indices[0]]\n",
    "    top_k_confidences = top_k_probs[0].tolist()\n",
    "    \n",
    "    return top_k_emotions, top_k_confidences\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_english(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Translates the input text to English using GPT-4\n",
    "    \"\"\"\n",
    "    translate_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4\")\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    chain = translate_model | parser\n",
    "\n",
    "    template = \"\"\"\n",
    "    You are a helpful AI assistant that translates text to English.\n",
    "    Please translate the following text to English if it's not already in English.\n",
    "    If the text is already in English, return it unchanged.\n",
    "\n",
    "    text: {text}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain = prompt | translate_model | parser\n",
    "\n",
    "    output = chain.invoke({\n",
    "        \"text\": text\n",
    "    })\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_emotion(text: str, emotion: str) -> str:\n",
    "    transform_model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-4\")\n",
    "    parser = StrOutputParser()\n",
    "\n",
    "    chain = transform_model | parser\n",
    "\n",
    "    template = \"\"\"\n",
    "    You are a helpful AI assistant that transforms a given text to another tone/emotion as specified by the user. The user\n",
    "    will specify the emotion like \"more sad\" or \"less happy\" etc. Also, if it is in another language, preserve it while transforming (no need to mention this in your response).\n",
    "\n",
    "    text: {text}\n",
    "\n",
    "    emotion: {emotion}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    chain = prompt | transform_model | parser\n",
    "\n",
    "    output = chain.invoke({\n",
    "        \"text\": text,\n",
    "        \"emotion\": emotion\n",
    "    })\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"I can’t believe how rude she was today. I was just asking a simple question and she snapped at me for no reason. It’s really frustrating when people are so disrespectful.\" #english (anger)\n",
    "text2 = \"রাতে একা বাড়িতে বসে থাকলে আমি ভয় পাই। প্রতিটি ছোট শব্দে আমার হৃদয় দ্রুত ধড়ফড় করতে থাকে, আর আমি ভাবতে থাকি, কোথাও কি কেউ আমার কাছে আসছে না? অন্ধকারে সব কিছু অদ্ভুত লাগে।\" #bengali (fear)\n",
    "text3 = \"ਅੱਜ ਮੈਨੂੰ ਬਹੁਤ ਖੁਸ਼ੀ ਹੋ ਰਹੀ ਹੈ ਕਿਉਂਕਿ ਮੈਂ ਆਪਣੇ ਕਠੋਰ ਮਿਹਨਤ ਦਾ ਫਲ ਪ੍ਰਾਪਤ ਕੀਤਾ ਹੈ। ਮੈਨੂੰ ਲੱਗਦਾ ਹੈ ਹੁਣ ਮੇਰੇ ਸਾਰੇ ਸੁਪਨੇ ਸੱਚੇ ਹੋ ਸਕਦੇ ਹਨ ਅਤੇ ਮੈਂ ਬਹੁਤ ਉਤਸ਼ਾਹਿਤ ਮਹਿਸੂਸ ਕਰ ਰਿਹਾ ਹਾਂ।\" #punjabi (joy)\n",
    "text4 = \"आज मुझे बहुत उदास महसूस हो रहा है। ऐसा लग रहा है जैसे सब कुछ गलत हो रहा है और मुझे नहीं पता कि इससे कैसे बाहर आऊं। कुछ अच्छा करने की कोशिश करता हूँ, लेकिन फिर भी दिल भारी है।\" #hindi (sadness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['anger', 'sadness', 'joy'], [0.9976836442947388, 0.001082075061276555, 0.00047183403512462974])\n"
     ]
    }
   ],
   "source": [
    "text = translate_to_english(text1)\n",
    "print(predict_top_emotions(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_emotion = \"less angry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I'm rather taken aback by her behavior today. I was merely asking a straightforward question and she responded somewhat hastily, without any apparent cause. It's somewhat disappointing when people lack basic courtesy.\"\n"
     ]
    }
   ],
   "source": [
    "print(transform_emotion(text, target_emotion))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
